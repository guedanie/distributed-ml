{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pydataset import data\n",
    "\n",
    "import pyspark\n",
    "import pyspark.ml\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "from wrangle import wrangle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use the `.randomSplit` method to split the 311 data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((684496, 21), (170773, 21))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shape(df: pyspark.sql.DataFrame):\n",
    "    return df.count(), len(df.columns)\n",
    "\n",
    "shape(train), shape(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a classification model to predict whether a case will be late or not (i.e. predict `case_late`). Experiment with different combinations of features and different classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " source_id            | 100137               \n",
      " dept_division        | 311 Call Center      \n",
      " case_id              | 1014263399           \n",
      " case_opened_date     | 2018-02-21 15:36:00  \n",
      " case_closed_date     | 2018-02-21 15:38:00  \n",
      " SLA_due_date         | 2018-03-02 15:36:00  \n",
      " case_late            | false                \n",
      " num_days_late        | -8.998854167000001   \n",
      " case_closed          | true                 \n",
      " service_request_type | Compliment           \n",
      " SLA_days             | 9.0                  \n",
      " case_status          | Closed               \n",
      " request_address      | 927  donaldson av... \n",
      " council_district     | 7                    \n",
      " num_weeks_late       | -1.2855505952857145  \n",
      " case_age             | 168                  \n",
      " days_to_closed       | 0                    \n",
      " case_lifetime        | 0                    \n",
      " department           | Customer Service     \n",
      " dept_subject_to_SLA  | true                 \n",
      " source_username      | Merlene Blodgett     \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are very little number of numerical values, we will likely have to use categorical values, along with a lot of HotEncoded items.\n",
    "\n",
    "Here the the three values that I think will be most useful:\n",
    "\n",
    "1. What department / dept_divsion is the request to. Given the track record, we may be able to predict if they majority of requests are late or not. \n",
    "1. The service request type. There is a record of some requests taking longer, on average, than others. This might be strong enough to help the model accurately predict our target. \n",
    "1. Date that the case was open. The majority of cases are open during the week, but are there any patterns where jobs opened on ceirtain days are less / more likely to be late? \n",
    "1. Council_district. We haven't explore this, but there might be evidence that depending on the district, ceirtain jobs may take longer / less time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will start with the department to predict if \n",
    "# the case will be late\n",
    "\n",
    "# How many dept_divisions are there?\n",
    "\n",
    "df.select(\"dept_division\").distinct().count()\n",
    "\n",
    "# becasue there are so many, we may fall to the curse of dimentionality\n",
    "# so we will only use department for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|          department|case_late|\n",
      "+--------------------+---------+\n",
      "|    Customer Service|    false|\n",
      "|DSD/Code Enforcement|    false|\n",
      "|DSD/Code Enforcement|    false|\n",
      "|DSD/Code Enforcement|    false|\n",
      "|DSD/Code Enforcement|    false|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    train.select(\"department\", \"case_late\")\n",
    "    .show(5)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RFormula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RFormula(formula=\"case_late ~ department\").fit(train)\n",
    "\n",
    "train_input = rf.transform(train).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_input = rf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------\n",
      " features | (7,[6],[1.0]) \n",
      " label    | 0.0           \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_input.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_c293e43b3819, numClasses = 2, numFeatures = 7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "# lr.explainParams() # to show all of the hyperparams\n",
    "lr_fit = lr.fit(train_input)\n",
    "lr_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary at 0x1223e0e10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary = lr_fit.summary\n",
    "training_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6234431279234867"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8889255744372502"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.622068653787877"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = pyspark.ml.evaluation.BinaryClassificationEvaluator()\n",
    "test_auc = evaluator.evaluate(lr_fit.transform(rf.transform(test)))\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " source_id            | 100137               \n",
      " dept_division        | 311 Call Center      \n",
      " case_id              | 1014263399           \n",
      " case_opened_date     | 2018-02-21 15:36:00  \n",
      " case_closed_date     | 2018-02-21 15:38:00  \n",
      " SLA_due_date         | 2018-03-02 15:36:00  \n",
      " case_late            | false                \n",
      " num_days_late        | -8.998854167000001   \n",
      " case_closed          | true                 \n",
      " service_request_type | Compliment           \n",
      " SLA_days             | 9.0                  \n",
      " case_status          | Closed               \n",
      " request_address      | 927  donaldson av... \n",
      " council_district     | 7                    \n",
      " num_weeks_late       | -1.2855505952857145  \n",
      " case_age             | 168                  \n",
      " days_to_closed       | 0                    \n",
      " case_lifetime        | 0                    \n",
      " department           | Customer Service     \n",
      " dept_subject_to_SLA  | true                 \n",
      " source_username      | Merlene Blodgett     \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=RandomForestClassifier_d23196f8f23e) with 3 trees"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(featuresCol = \"features\", labelCol = \"label\", numTrees = 3, maxDepth = 2, seed=42)\n",
    "rfc_fit = rfc.fit(train_input)\n",
    "rfc_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+--------------------+--------------------+----------+\n",
      "|     features|label|       rawPrediction|         probability|prediction|\n",
      "+-------------+-----+--------------------+--------------------+----------+\n",
      "|(7,[6],[1.0])|  0.0|[0.90492982422414...|[0.30164327474138...|       1.0|\n",
      "+-------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rfc_fit.transform(train_input)\n",
    "predictions.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 0.5719910826943205\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 0.5707985065354458\n"
     ]
    }
   ],
   "source": [
    "predictions = rfc_fit.transform(test_input)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling 2\n",
    "\n",
    "Now we will try to model using both `department` and `service_request_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import  OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train.select(\"department\", \"service_request_type\", \"case_late\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoder = OneHotEncoder()\n",
    "# encoder_fit = encoder.fit(X_train.select(\"department\", \"service_request_tyoe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RFormula(formula=\"case_late ~ department + service_request_type\").fit(train)\n",
    "\n",
    "train_input = rf.transform(train).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = rf.transform(test).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_e1e094df505b, numClasses = 2, numFeatures = 340"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "# lr.explainParams() # to show all of the hyperparams\n",
    "lr_fit = lr.fit(train_input)\n",
    "lr_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary at 0x122560d10>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary = lr_fit.summary\n",
    "training_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8162315987666309"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006626773567705"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential error:\n",
    "\n",
    "* evaluation\n",
    "* input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = pyspark.ml.evaluation.BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = lr_fit.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(340,[6,154],[1.0...|  0.0|[3.51747782592652...|[0.97118099611191...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_auc = evaluator.evaluate(test_predictions)\n",
    "\n",
    "# calculate values manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " source_id            | 100137               \n",
      " dept_division        | 311 Call Center      \n",
      " case_id              | 1014263399           \n",
      " case_opened_date     | 2018-02-21 15:36:00  \n",
      " case_closed_date     | 2018-02-21 15:38:00  \n",
      " SLA_due_date         | 2018-03-02 15:36:00  \n",
      " case_late            | false                \n",
      " num_days_late        | -8.998854167000001   \n",
      " case_closed          | true                 \n",
      " service_request_type | Compliment           \n",
      " SLA_days             | 9.0                  \n",
      " case_status          | Closed               \n",
      " request_address      | 927  donaldson av... \n",
      " council_district     | 7                    \n",
      " num_weeks_late       | -1.2855505952857145  \n",
      " case_age             | 168                  \n",
      " days_to_closed       | 0                    \n",
      " case_lifetime        | 0                    \n",
      " department           | Customer Service     \n",
      " dept_subject_to_SLA  | true                 \n",
      " source_username      | Merlene Blodgett     \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=RandomForestClassifier_efdaf48239f3) with 1 trees"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(featuresCol = \"features\", labelCol = \"label\", numTrees = 1, maxDepth = 10, seed=42)\n",
    "rfc_fit = rfc.fit(train_input)\n",
    "rfc_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(340,[6,154],[1.0...|  0.0|[0.91734251519362...|[0.91734251519362...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rfc_fit.transform(train_input)\n",
    "predictions.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 0.64119186823807\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(340,[6,154],[1.0...|  0.0|[0.91734251519362...|[0.91734251519362...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = rfc_fit.transform(test_input)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "# print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "|            features|       label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "|(340,[6,154],[1.0...|-10.99946759|[0.91734251519362...|[0.91734251519362...|       0.0|\n",
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a regression model to predict how many days late a case will be (i.e. predict `num_days_late`). Experiment with different combinations of features and different regression algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " source_id            | 100137               \n",
      " dept_division        | 311 Call Center      \n",
      " case_id              | 1014263399           \n",
      " case_opened_date     | 2018-02-21 15:36:00  \n",
      " case_closed_date     | 2018-02-21 15:38:00  \n",
      " SLA_due_date         | 2018-03-02 15:36:00  \n",
      " case_late            | false                \n",
      " num_days_late        | -8.998854167000001   \n",
      " case_closed          | true                 \n",
      " service_request_type | Compliment           \n",
      " SLA_days             | 9.0                  \n",
      " case_status          | Closed               \n",
      " request_address      | 927  donaldson av... \n",
      " council_district     | 7                    \n",
      " num_weeks_late       | -1.2855505952857145  \n",
      " case_age             | 168                  \n",
      " days_to_closed       | 0                    \n",
      " case_lifetime        | 0                    \n",
      " department           | Customer Service     \n",
      " dept_subject_to_SLA  | true                 \n",
      " source_username      | Merlene Blodgett     \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For predicting num_days_late, we will use the same features as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "varIdxer = StringIndexer(inputCol='department',outputCol='varIdx').fit(train)\n",
    "df_1 = varIdxer.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = OneHotEncoder(inputCol=\"varIdx\", outputCol=\"varCat\").transform(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"varCat\"],outputCol=\"features\")\n",
    "df_1 =  assembler.transform(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.withColumnRenamed(\"num_days_late\", \"y\").select(\"features\", \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|     features|                 y|\n",
      "+-------------+------------------+\n",
      "|(7,[6],[1.0])|-8.998854167000001|\n",
      "+-------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol='y',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_fit = lr.fit(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_summary = lr_fit.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17058279341800175, 161.05689305874301)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.r2, training_summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66.17415734155266, 25939.322801735383)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.meanAbsoluteError, training_summary.meanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivaraite Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modeling = train.withColumnRenamed(\"num_days_late\", \"y\").select(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = train.select(\"department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[y: string]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_modeling.join(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed department\n",
      "Encoded department\n",
      "Indexed service_request_type\n",
      "Encoded service_request_type\n"
     ]
    }
   ],
   "source": [
    "features = [\"department\", \"service_request_type\"]\n",
    "# string_indexer_df = pd.DataFrame()\n",
    "train_modeling = train.withColumnRenamed(\"num_days_late\", \"y\").select(\"y\")\n",
    "\n",
    "for i in features:\n",
    "        varIdxer = StringIndexer(inputCol=i,outputCol=f'varIdx_{i}').fit(train)\n",
    "        df_1 = varIdxer.transform(train)\n",
    "        print(f\"Indexed {i}\")\n",
    "        df_1 = OneHotEncoder(inputCol=f\"varIdx_{i}\", outputCol=f\"varCat_{i}\").transform(df_1)\n",
    "        print(f\"Encoded {i}\")\n",
    "        train_modeling.join\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[f\"varCat_{features[0]}, varCat_{features[1]}\"],outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------\n",
      " source_id                   | 100137               \n",
      " dept_division               | 311 Call Center      \n",
      " case_id                     | 1014263399           \n",
      " case_opened_date            | 2018-02-21 15:36:00  \n",
      " case_closed_date            | 2018-02-21 15:38:00  \n",
      " SLA_due_date                | 2018-03-02 15:36:00  \n",
      " case_late                   | false                \n",
      " num_days_late               | -8.998854167000001   \n",
      " case_closed                 | true                 \n",
      " service_request_type        | Compliment           \n",
      " SLA_days                    | 9.0                  \n",
      " case_status                 | Closed               \n",
      " request_address             | 927  donaldson av... \n",
      " council_district            | 7                    \n",
      " num_weeks_late              | -1.2855505952857145  \n",
      " case_age                    | 168                  \n",
      " days_to_closed              | 0                    \n",
      " case_lifetime               | 0                    \n",
      " department                  | Customer Service     \n",
      " dept_subject_to_SLA         | true                 \n",
      " source_username             | Merlene Blodgett     \n",
      " varIdx_service_request_type | 147.0                \n",
      " varCat_service_request_type | (333,[147],[1.0])    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "varIdxer = StringIndexer(inputCol='department',outputCol='varIdx').fit(train)\n",
    "df_1 = varIdxer.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = OneHotEncoder(inputCol=\"varIdx\", outputCol=\"varCat\").transform(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"varCat\"],outputCol=\"features\")\n",
    "df_1 =  assembler.transform(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.withColumnRenamed(\"num_days_late\", \"y\").select(\"features\", \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|     features|                 y|\n",
      "+-------------+------------------+\n",
      "|(7,[6],[1.0])|-8.998854167000001|\n",
      "+-------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol='y',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_fit = lr.fit(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_summary = lr_fit.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17058279341800175, 161.05689305874301)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.r2, training_summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66.17415734155266, 25939.322801735383)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.meanAbsoluteError, training_summary.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "varIdxer = StringIndexer(inputCol='department',outputCol='varIdx').fit(train)\n",
    "df_1 = varIdxer.transform(train)\n",
    "\n",
    "df_1 = OneHotEncoder(inputCol=\"varIdx\", outputCol=\"varCat\").transform(df_1)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"varCat\"],outputCol=\"features\")\n",
    "df_1 =  assembler.transform(df_1)\n",
    "\n",
    "df_1 = df_1.withColumnRenamed(\"num_days_late\", \"y\").select(\"features\", \"y\")\n",
    "\n",
    "df_1.show(1)\n",
    "\n",
    "df_1 = df_1.na.drop()\n",
    "\n",
    "lr = LinearRegression(labelCol='y',featuresCol='features')\n",
    "\n",
    "lr_fit = lr.fit(df_1)\n",
    "\n",
    "training_summary = lr_fit.summary\n",
    "\n",
    "training_summary.r2, training_summary.rootMeanSquaredError\n",
    "\n",
    "training_summary.meanAbsoluteError, training_summary.meanSquaredError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
